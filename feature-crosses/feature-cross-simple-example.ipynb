{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example taken from Google ML Crash Course:\n",
    "https://developers.google.com/machine-learning/crash-course/feature-crosses/encoding-nonlinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import tensorflow as tf \n",
    "\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = \"{:.1f}\".format\n",
    "\n",
    "# pd.show_versions()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Problem"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the DataSet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50 data points per category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the random data set for sick trees\n",
    "\n",
    "Scale and shift the (0, 1) range from np.random.random to (-5, 5) respectively (0, 5)\n",
    "\n",
    "See also here: https://stackoverflow.com/questions/59389241/how-to-generate-a-random-float-in-range-1-1-using-numpy-random-rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_x, min_x = 5, -5\n",
    "range_size = (max_x - min_x)\n",
    "sick_x = np.random.random([N]) * range_size + min_x\n",
    "\n",
    "max_y, min_y = 0, -5\n",
    "range_size = (max_y - min_y)\n",
    "sick_y = np.random.random([N]) * range_size + min_y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the randomn data set for healthy trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_x, min_x = 5, -5\n",
    "range_size = (max_x - min_x)\n",
    "healthy_x = np.random.random([N]) * range_size + min_x\n",
    "\n",
    "max_y, min_y = 5, 0\n",
    "range_size = (max_y - min_y)\n",
    "healthy_y = np.random.random([N]) * range_size + min_y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.scatter(sick_x, sick_y)\n",
    "plt.scatter(healthy_x, healthy_y)\n",
    "\n",
    "plt.xlabel('x') \n",
    "plt.ylabel('y') \n",
    "\n",
    "plt.title(\"Training Data\") \n",
    "plt.show() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the x and y arrays\n",
    "sick_trees = np.vstack((sick_x, sick_y)).T\n",
    "healthy_trees = np.vstack((healthy_x, healthy_x)).T\n",
    "\n",
    "data_column_names = ['x', 'y']\n",
    "\n",
    "df_sick = pd.DataFrame(data=sick_trees, columns=data_column_names)\n",
    "df_sick['status'] = 1\n",
    "\n",
    "df_healthy = pd.DataFrame(data=healthy_trees, columns=data_column_names)\n",
    "df_healthy['status'] = 0\n",
    "\n",
    "# append is deprecated since pandas 1.4.0\n",
    "# train_df = df_sick.append(df_healthy, ignore_index=True)\n",
    "train_df = pd.concat([df_sick, df_healthy], ignore_index=True)\n",
    "\n",
    "# Shuffle the examples.\n",
    "shuffled_train_df = train_df.reindex(np.random.permutation(train_df.index)) \n",
    "shuffled_train_df.head(100)\n",
    "\n",
    "# Print the entire DataFrame\n",
    "# print(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and Train Model Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Define the functions that build and train a model\n",
    "def build_model(my_learning_rate):\n",
    "  \"\"\"Create and compile a simple linear regression model.\"\"\"\n",
    "  # Most simple tf.keras models are sequential.\n",
    "  model = tf.keras.models.Sequential()\n",
    "\n",
    "  # Add one linear layer to the model to yield a simple linear regressor.\n",
    "  model.add(tf.keras.layers.Dense(30, input_shape=(30,2)))\n",
    "  # model.add(tf.keras.layers.Dense(32, \n",
    "  #                                   input_shape = (x_train.shape[1],), \n",
    "  #                                   activation = 'sigmoid'))\n",
    "\n",
    "  # Compile the model topography into code that TensorFlow can efficiently\n",
    "  # execute. Configure training to minimize the model's mean squared error. \n",
    "  model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=my_learning_rate),\n",
    "                loss=\"mean_squared_error\",\n",
    "                metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "  return model               \n",
    "\n",
    "\n",
    "def train_model(model, x, y, my_epochs, \n",
    "                my_batch_size=None, my_validation_split=0.1):\n",
    "  \"\"\"Feed a dataset into the model in order to train it.\"\"\"\n",
    "\n",
    "  history = model.fit(x=x,\n",
    "                      y=y,\n",
    "                      batch_size=my_batch_size,\n",
    "                      epochs=my_epochs,\n",
    "                      validation_split=my_validation_split)\n",
    "\n",
    "  # Gather the model's trained weight and bias.\n",
    "  trained_weight = model.get_weights()[0]\n",
    "  trained_bias = model.get_weights()[1]\n",
    "\n",
    "  # The list of epochs is stored separately from the \n",
    "  # rest of history.\n",
    "  epochs = history.epoch\n",
    "  \n",
    "  # Isolate the root mean squared error for each epoch.\n",
    "  hist = pd.DataFrame(history.history)\n",
    "  rmse = hist[\"root_mean_squared_error\"]\n",
    "\n",
    "  return epochs, rmse, history.history   \n",
    "\n",
    "print(\"Defined the build_model and train_model functions.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_the_model(trained_weight, trained_bias, feature, label):\n",
    "  \"\"\"Plot the trained model against 200 random training examples.\"\"\"\n",
    "\n",
    "  # Label the axes.\n",
    "  plt.xlabel(feature)\n",
    "  plt.ylabel(label)\n",
    "\n",
    "  # Create a scatter plot from 200 random points of the dataset.\n",
    "  random_examples = training_df.sample(n=200)\n",
    "  plt.scatter(random_examples[feature], random_examples[label])\n",
    "\n",
    "  # Create a red line representing the model. The red line starts\n",
    "  # at coordinates (x0, y0) and ends at coordinates (x1, y1).\n",
    "  x0 = 0\n",
    "  y0 = trained_bias\n",
    "  x1 = random_examples[feature].max()\n",
    "  y1 = trained_bias + (trained_weight * x1)\n",
    "  plt.plot([x0, x1], [y0, y1], c='r')\n",
    "\n",
    "  # Render the scatter plot and the red line.\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "def plot_the_loss_curve(epochs, rmse):\n",
    "  \"\"\"Plot a curve of loss vs. epoch.\"\"\"\n",
    "\n",
    "  plt.figure()\n",
    "  plt.xlabel(\"Epoch\")\n",
    "  plt.ylabel(\"Root Mean Squared Error\")\n",
    "\n",
    "  plt.plot(epochs, rmse, label=\"Loss\")\n",
    "  plt.legend()\n",
    "  plt.ylim([rmse.min()*0.97, rmse.max()])\n",
    "  plt.show()  \n",
    "\n",
    "print(\"Defined the plot_the_model and plot_the_loss_curve functions.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following variables are the hyperparameters.\n",
    "learning_rate = 0.01\n",
    "epochs = 30\n",
    "batch_size = 30\n",
    "\n",
    "# Specify the feature and the label.\n",
    "my_feature = \"total_rooms\"  # the total number of rooms on a specific city block.\n",
    "my_label=\"median_house_value\" # the median value of a house on a specific city block.\n",
    "# That is, you're going to create a model that predicts house value based \n",
    "# solely on total_rooms.  \n",
    "\n",
    "# Discard any pre-existing version of the model.\n",
    "my_model = None\n",
    "\n",
    "# Invoke the functions.\n",
    "my_model = build_model(learning_rate)\n",
    "weight, bias, epochs, rmse = train_model(my_model, \n",
    "                                        shuffled_train_df.drop('status', axis=1),\n",
    "                                        shuffled_train_df[['status']],\n",
    "                                        epochs, batch_size)\n",
    "\n",
    "print(\"\\nThe learned weight for your model is %.4f\" % weight)\n",
    "print(\"The learned bias for your model is %.4f\\n\" % bias )\n",
    "\n",
    "plot_the_model(weight, bias, my_feature, my_label)\n",
    "plot_the_loss_curve(epochs, rmse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Linear Problem"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the sample data set\n",
    "\n",
    "Scale and shift the (0, 1) range from np.random.random to (-5, 5).\n",
    "\n",
    "See also here: https://stackoverflow.com/questions/59389241/how-to-generate-a-random-float-in-range-1-1-using-numpy-random-rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "max_val, min_val = 5, -5\n",
    "range_size = (max_val - min_val)  # 2\n",
    "x = np.random.random([N]) * range_size + min_val\n",
    "y = np.random.random([N]) * range_size + min_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.scatter(x, y)\n",
    "\n",
    "plt.xlabel('x') \n",
    "plt.ylabel('y') \n",
    "\n",
    "plt.title(\"Training Data\") \n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
